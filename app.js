import 'dotenv/config';
import express from 'express';
import http from 'http';
import { Server as SocketIOServer } from 'socket.io';
import { fileURLToPath } from 'url';
import OpenAI from 'openai';
import path from 'path';
import fs from 'fs/promises'; // fs.promises ì‚¬ìš©

const app = express();
const server = http.createServer(app);
const io = new SocketIOServer(server);

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// ì„œë²„ í¬íŠ¸
const port = 3000;

// __dirname ì„¤ì •
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// âœ… ë¯¸ë“¤ì›¨ì–´
app.use(express.json()); // JSON ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
app.use(express.urlencoded({ extended: true })); // URL-encoded ìš”ì²­ íŒŒì‹±
app.use(express.static(path.join(__dirname, 'public')));

// âœ… í˜ì´ì§€ ë¼ìš°íŠ¸
app.get('/', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/page1', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/page2', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'indexPage2.html'));
});

app.get('/page3', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'indexPage3.html'));
});

// âœ… JSON íŒŒì¼ ì œê³µ
app.get('/scenarioMakingPrompt.json', async (req, res) => {
  const filePath = path.join(__dirname, 'scenarioMakingPrompt.json');
  try {
    // íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    await fs.access(filePath);
    res.sendFile(filePath);
  } catch (error) {
    console.error('âŒ Failed to serve scenarioMakingPrompt.json:', error);
    res.status(404).send('scenarioMakingPrompt.json not found');
  }
});

// âœ… JSON íŒŒì¼ ì—…ë°ì´íŠ¸ ë¼ìš°íŠ¸
app.post('/update-json', async (req, res) => {
  const jsonData = req.body; // í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ì€ JSON ë°ì´í„°
  const filePath = path.join(__dirname, 'scenarioMakingPrompt.json'); // ì—…ë°ì´íŠ¸í•  íŒŒì¼ ê²½ë¡œ
  try {
    if (!jsonData || Object.keys(jsonData).length === 0) {
      console.error('No JSON data received');
      return res.status(400).send('No JSON data received');
    }
    await fs.writeFile(filePath, JSON.stringify(jsonData, null, 2), 'utf8');
    console.log('âœ… JSON íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.');
    res.status(200).send('JSON file updated successfully');
  } catch (err) {
    console.error('âŒ JSON íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', err);
    res.status(500).send('Failed to update JSON file');
  }
});

// í˜„ì¬ ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ì¶”ì 
let clientCount = 0;

io.on("connection", (socket) => {
  let responseText = "";
  console.log(`Client connected`);

  // ì²« ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
  socket.on("firstPrompting", async ({ prompt }) => {
    console.log('Client sent prompt:', prompt);
    try {
      const firstInputText =
        "ë„ˆê°€ ìœ ëŠ¥í•œ ì„œë¹„ìŠ¤ë””ìì´ë„ˆê°€ ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³ , ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê°œì„ í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ì´ ë”ìš± í’ë¶€í•´ì§ˆ ìˆ˜ ìˆë„ë¡ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì¶”ê°€í•´ì¤˜. í˜„ì‹¤ì ì¸ ì•„ì´ë””ì–´ë¡œ í’ë¶€í•œ ì‚¬ìš©ì ê²½í—˜ì„ ì°½ì¶œí•  ìˆ˜ ìˆë„ë¡ í•´ì¤˜. ì£¼ì–´ì§„ ì‹œë‚˜ë¦¬ì˜¤ì— ì–¸ê¸‰ëœ ì‚¬ìš©ìì˜ ì´ë¦„, ì¥ì†Œì˜ íŠ¹ì§• ë“±ì˜ ë¬˜ì‚¬ë¥¼ ìƒëµí•˜ì§€ ë§ˆ."
        + "ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤: " + prompt;

      // OpenAI GPT-4 ëª¨ë¸ í˜¸ì¶œ
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: firstInputText }],
      });

      // ì²« ë²ˆì§¸ ì‘ë‹µ ì €ì¥
      responseText = completion.choices[0].message.content;
      console.log(`OpenAI first response:`, responseText);

      // ì²« ë²ˆì§¸ ì‘ë‹µì„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
      socket.emit("openai response", { response: responseText });
    } catch (error) {
      console.error("Error during first prompt:", error);
      socket.emit("openai response", {
        error: "An error occurred while contacting the OpenAI API.",
      });
    }
  });

  // ë‘ ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ (ì´ì „ ì‘ë‹µì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©)
  socket.on("secondPrompting", async () => {

    const secondInputText =
      "Main Artifact: ì„œë¹„ìŠ¤ì˜ physical artifactì˜ ì„œë¹„ìŠ¤ê°€ ì´ë£¨ì–´ì§€ëŠ” ì¥ì†Œì´ë‹¤." +
      "Sub Artifact: Main Artifactì˜ í•˜ìœ„ í•­ëª©ìœ¼ë¡œ, í•´ë‹¹ ì¥ì†Œì—ì„œ ì‚¬ìš©ìê°€ ì ‘í•˜ëŠ” í„°ì¹˜í¬ì¸íŠ¸ë¥¼ ì¼ì»«ëŠ”ë‹¤." +
      "]\n" +
      "ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤: " + responseText +
      "]\n" +
      "ì´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„œìˆ ë˜ê³  ìˆëŠ” Main Artifactì™€ Sub Artifact, Userë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤. ì¶œë ¥ë˜ëŠ” í…ìŠ¤íŠ¸ëŠ” ë‹¤ìŒ [format]ì„ *ë°˜ë“œì‹œ* ë”°ë¥¼ ê²ƒ. [format] ì´ì™¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.\n" +
      "ë‹¹ì‹ ì˜ ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”. ë‹¨. mainArtifactì˜ ê°œìˆ˜ëŠ” 3ê°œë¥¼ ë„˜ì§€ ë§ ê²ƒ.\n" +
      "ì¶œë ¥ í˜•ì‹:\n" +
      `{
    "artifacts": [
      {
        "mainArtifact": "Main Artifact 1",
        "subArtifacts": ["Sub Artifact 1-1", "Sub Artifact 1-2"]
      },
      {
        "mainArtifact": "Main Artifact 2",
        "subArtifacts": ["Sub Artifact 2-1", "Sub Artifact 2-2"]
      }
    ],
    "users": ["User 1", "User 2"]
  }`;


    try {
      // ì²« ë²ˆì§¸ ì‘ë‹µì¸ responseTextë¥¼ ìƒˆë¡œìš´ ì…ë ¥(prompt)ë¡œ ì‚¬ìš©
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "system", content: secondInputText }],
      });

      // ë‘ ë²ˆì§¸ ì‘ë‹µ ì €ì¥
      const secondResponseText = completion.choices[0].message.content;
      console.log(`OpenAI second response: `, secondResponseText);

      // ìµœì¢… ì‘ë‹µì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡ (ì‚¬ì´í´ ì¢…ë£Œ)
      socket.emit("final openai response", { response: secondResponseText });
    } catch (error) {
      console.error("Error during second prompt:", error);
      socket.emit("final openai response", {
        error: "An error occurred while re-asking the OpenAI API.",
      });
    }
  });

  socket.on("scenarioPrompting", async ({ prompt }) => {
    console.log('ğŸ“¤ Client sent prompt:', prompt);

    try {
      // âœ… í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ êµ¬ì„±
      const scenarioInputText = "json íŒŒì¼" + prompt
        + "]\n"
        + ": ë„ˆëŠ” ìœ ëŠ¥í•œ ì„œë¹„ìŠ¤ ë””ìì´ë„ˆì•¼. ì´ json íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ Key Interactions, Service Outcome & Valueë¥¼ í¬í•¨í•œ **ë¬´ì¡°ê±´ 5ë¬¸ì¥**ì˜ ì„œë¹„ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•´ì¤˜.";

      // âœ… OpenAI API í˜¸ì¶œ
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "system", content: scenarioInputText }],
      });

      // âœ… OpenAI ì‘ë‹µ í™•ì¸
      const responseText = completion.choices[0]?.message?.content;
      if (!responseText) {
        throw new Error("OpenAI API returned an empty response.");
      }

      console.log('âœ… OpenAI response:', responseText);

      // âœ… í´ë¼ì´ì–¸íŠ¸ë¡œ ì‘ë‹µ ì „ì†¡
      socket.emit("scenario response", { response: responseText });
    } catch (error) {
      console.error("âŒ Error during scenarioPrompting:", error);

      // âœ… ì—ëŸ¬ í•¸ë“¤ë§
      socket.emit("scenario response", {
        error: "An error occurred while contacting the OpenAI API.",
        details: error.message, // ë””ë²„ê¹…ì„ ìœ„í•´ ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨
      });
    }
  });

  socket.on("generateImage", async ({ step1Text, step2Text, step3Text, step4Text, step5Text }) => {
    console.log('ğŸ“¤ Client sent image prompts:', { step1Text, step2Text, step3Text, step4Text, step5Text });

    if (!step1Text || !step2Text || !step3Text || !step4Text || !step5Text) {
      console.error('âŒ Missing step data from client');
      return socket.emit('image response', {
        error: 'Missing step data from client.'
      });
    }

    try {
      // âœ… í”„ë¡¬í”„íŠ¸ ë°°ì—´ ì¤€ë¹„
      const steps = [step1Text, step2Text, step3Text, step4Text, step5Text];
      const imageUrls = [];
  
      // ìŠ¤íƒ€ì¼ì„ ëª…í™•í•˜ê²Œ ì„¤ì •í•œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
      const baseStyleDescription = "The illustration should be minimalist, with a white background, no excessive details or complex elements, and a soft, gentle appearance. ì´ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì˜í™”ì˜ í•œ ì¥ë©´ì´ë¼ê³  ìƒê°í•˜ê³ , ê·¸ ì¥ë©´ í•œ ì»·ì„ í¬ì°©í•œë‹¤ê³  ìƒê°í•´ë´. "
        + "The art style is reminiscent of 2D Disney animation, with smooth, clean lines and a soft, whimsical feel. "
        + "The illustration is lighthearted and warm, with a minimalist design that highlights the simplicity of the scene. ";
  
      for (let i = 0; i < steps.length; i++) {
        const sceneDescription = i === 0
          ? `Scene 1: Introduce the scenario. ${steps[i]}`
          : `Scene ${i + 1}: Continuation of the previous scene, with ${steps[i]}`;
  
        const imageInputText = baseStyleDescription
          + "\n " + sceneDescription;
  
        console.log(`ğŸ“¤ Generating image for Step ${i + 1}:`, imageInputText);
  
        // âœ… OpenAI DALL-E API í˜¸ì¶œ
        const response = await openai.images.generate({
          model: "dall-e-3",
          prompt: imageInputText,
          n: 1,
          size: "1024x1024",
        });
  
        // âœ… ì´ë¯¸ì§€ URL ì¶”ì¶œ
        const imageUrl = response.data[0]?.url;
        if (!imageUrl) {
          throw new Error(`Failed to retrieve image URL for Step ${i + 1}`);
        }
  
        console.log(`âœ… Image URL for Step ${i + 1}:`, imageUrl);
  
        imageUrls.push({ step: i + 1, imageUrl });
      }
  
      // âœ… í´ë¼ì´ì–¸íŠ¸ë¡œ ì´ë¯¸ì§€ URL ëª©ë¡ ì „ì†¡
      socket.emit("image response", { imageUrls });
    } catch (error) {
      console.error("âŒ Error during image generation:", error);
  
      // âœ… ì—ëŸ¬ í•¸ë“¤ë§
      socket.emit("image response", {
        error: "An error occurred while generating the images.",
        details: error.message,
      });
    }
  });

  // í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ ì‹œ ì²˜ë¦¬
  socket.on("disconnect", () => {
    console.log(`Client disconnected`);
  });
});

// ì„œë²„ ì‹œì‘
server.listen(port, () => {
  console.log(`Server is running at http://localhost:${port}`);

});